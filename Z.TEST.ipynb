{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "radio-corporation",
   "metadata": {},
   "source": [
    "## kf debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "round-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = boto3.Session()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "sm   = sess.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "# sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "affiliated-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_image:  763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:1.15.2-cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inference_image = '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:1.15.2-cpu'\n",
    "print(\"inference_image: \", inference_image)\n",
    "model_data = 's3://sagemaker-ap-northeast-2-189546603447/jobs/TrainingJob-20210408085502-KH4I/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "elegant-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data=model_data,\n",
    "              role=role,\n",
    "              source_dir=\"code222\",              \n",
    "              entry_point='inference2.py',\n",
    "              image_uri = inference_image\n",
    "             ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "weird-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/kubeflow-pipelines-sagemaker-examples'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "silent-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to yxvtnirykg-algo-1-y8yxw\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:starting services\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:nginx config: \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m load_module modules/ngx_http_js_module.so;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m worker_processes auto;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m daemon off;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m error_log  /dev/stderr error;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m events {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m http {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   default_type application/json;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   js_include tensorflow-serving.js;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   upstream tfs_upstream {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     server localhost:8501;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   upstream gunicorn_upstream {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   server {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     client_body_buffer_size 100m;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     subrequest_output_buffer_size 100m;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     set $tfs_version 2.0;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     set $default_tfs_model None;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     location /tfs {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_redirect off;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_pass_request_headers off;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_set_header Content-Type 'application/json';\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_set_header Accept 'application/json';\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_pass http://tfs_upstream;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     location /ping {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_pass http://gunicorn_upstream/ping;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     location /invocations {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_pass http://gunicorn_upstream/invocations;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     location /models {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         proxy_pass http://gunicorn_upstream/models;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     location / {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:tfs_utils:using default model name: saved_model\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:tfs_utils:tensorflow serving model config: \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m model_config_list: {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   config: {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     name: \"saved_model\",\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     base_path: \"/opt/ml/model/tensorflow/saved_model\",\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:using default model name: saved_model\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:tensorflow serving model config: \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m model_config_list: {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   config: {\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     name: \"saved_model\",\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     base_path: \"/opt/ml/model/tensorflow/saved_model\",\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:tensorflow version info:\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m TensorFlow ModelServer: 2.0.0+dev.sha.642edcd\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m TensorFlow Library: 2.0.0\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0 \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:started tensorflow serving (pid: 8)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:installing packages from requirements.txt...\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.088815: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.088839: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: saved_model\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.189257: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: saved_model version: 0} exhausted max_num_retries: 0\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.189280: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: saved_model version: 0}\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.189286: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: saved_model version: 0}\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.189293: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: saved_model version: 0}\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.189308: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/tensorflow/saved_model/0\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.233612: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.298783: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.308610: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:50.447658: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m Collecting Pillow\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   Downloading Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |                                | 10 kB 31.8 MB/s eta 0:00:012021-04-08 09:08:51.004547: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: /opt/ml/model/tensorflow/saved_model/0\n",
      "\u001b[K     |█████████                       | 829 kB 2.6 MB/s eta 0:00:012021-04-08 09:08:51.176455: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 987143 microseconds.\n",
      "\u001b[K     |██████████                      | 931 kB 2.6 MB/s eta 0:00:012021-04-08 09:08:51.190237: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /opt/ml/model/tensorflow/saved_model/0/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[K     |███████████                     | 1.0 MB 2.6 MB/s eta 0:00:012021-04-08 09:08:51.204055: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: saved_model version: 0} exhausted max_num_retries: 0\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:51.204076: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: saved_model version: 0}\n",
      "\u001b[K     |███████████▊                    | 1.1 MB 2.6 MB/s eta 0:00:012021-04-08 09:08:51.212332: I tensorflow_serving/model_servers/server.cc:353] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[K     |████████████                    | 1.1 MB 2.6 MB/s eta 0:00:01[warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 2021-04-08 09:08:51.217165: I tensorflow_serving/model_servers/server.cc:373] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.19.5)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m Installing collected packages: Pillow\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m Successfully installed Pillow-8.2.0\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:gunicorn command: gunicorn -b unix:/tmp/gunicorn.sock -k gevent --chdir /sagemaker --pythonpath /opt/ml/model/code -e TFS_GRPC_PORT=9000 -e SAGEMAKER_MULTI_MODEL=False -e SAGEMAKER_SAFE_PORT_RANGE=None python_service:app\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:gunicorn version info:\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m gunicorn (version 20.0.4)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:started gunicorn (pid: 363)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m [2021-04-08 09:08:52 +0000] [363] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:gunicorn server is ready!\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m [2021-04-08 09:08:52 +0000] [363] [INFO] Listening at: unix:/tmp/gunicorn.sock (363)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m [2021-04-08 09:08:52 +0000] [363] [INFO] Using worker: gevent\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m [2021-04-08 09:08:52 +0000] [367] [INFO] Booting worker with pid: 367\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:nginx version info:\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m nginx version: nginx/1.18.0\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m built by gcc 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m built with OpenSSL 1.1.1  11 Sep 2018\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m TLS SNI support enabled\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.18.0/debian/debuild-base/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:__main__:started nginx (pid: 368)\n",
      "!\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 172.19.0.1 - - [08/Apr/2021:09:08:57 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.4\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "endpont_name = 'local-endpoint'\n",
    "\n",
    "instance_type='local'\n",
    "deployed_model = model.deploy(\n",
    "                             endpoint_name= endpont_name,\n",
    "                             initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "wrapped-endorsement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Error: 415, Unsupported content type \"application/json\"'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:python_service:http://gunicorn_upstream/invocations\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m INFO:tfs_utils:sagemaker tfs attributes: \n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m {}\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m ERROR:python_service:exception handling request: Error: 415, Unsupported content type \"application/json\"\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   File \"/sagemaker/python_service.py\", line 252, in _handle_invocation_post\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     res.body, res.content_type = self._handlers(data, context)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   File \"/sagemaker/python_service.py\", line 281, in handler\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     processed_input = custom_input_handler(data, context)\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   File \"/opt/ml/model/code/inference.py\", line 44, in input_handler\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     _return_error(415, 'Unsupported content type \"{}\"'.format(context.request_content_type or 'Unknown'))\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m   File \"/opt/ml/model/code/inference.py\", line 65, in _return_error\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m     raise ValueError('Error: {}, {}'.format(str(code), message))\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m ValueError: Error: 415, Unsupported content type \"application/json\"\n",
      "\u001b[36myxvtnirykg-algo-1-y8yxw |\u001b[0m 172.19.0.1 - - [08/Apr/2021:09:09:14 +0000] \"POST /invocations HTTP/1.1\" 500 70 \"-\" \"python-urllib3/1.26.4\"\n"
     ]
    }
   ],
   "source": [
    "file_name = '1000_dog.png'\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "# print(\"Predicted class is {}\".format(np.argmax(predictor.predict(data)['predictions'])))    \n",
    "deployed_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "objective-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = deployed_model.endpoint_name\n",
    "\n",
    "# # deployed_model.content_type='application/x-image'    \n",
    "# deployed_model.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "biblical-lighting",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint local-endpoint of account 189546603447 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-6ec92bb7e02e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m response = client.invoke_endpoint(EndpointName= endpoint_name, \n\u001b[1;32m     11\u001b[0m                                   \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'application/x-image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                   Body=payload)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'airplane'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'automobile'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bird'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'frog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'horse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ship'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'truck'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint local-endpoint of account 189546603447 not found."
     ]
    }
   ],
   "source": [
    "import json, boto3\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "file_name = '1000_dog.png'\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    \n",
    "# print(\"payload: \\n\", payload)    \n",
    "\n",
    "response = client.invoke_endpoint(EndpointName= endpoint_name, \n",
    "                                  ContentType='application/x-image', \n",
    "                                  Body=payload)\n",
    "print(response['Body'].read())\n",
    "labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-circular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "removed-poland",
   "metadata": {},
   "source": [
    "## 엔드포인트 디버깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "classified-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "training_job_name='TrainingJob-20210408030418-BHHB'\n",
    "# inference_image = '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:1.15.2-cpu-py36-ubuntu18.04-v4.4'\n",
    "# inference_image = '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:1.15.2-cpu'\n",
    "\n",
    "cifar_model = TensorFlowModel(\n",
    "    name='kubeflow-debug',\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    "    # image_uri = inference_image,\n",
    "    model_data=\"s3://{}/{}/output/model.tar.gz\".format(bucket, training_job_name),\n",
    "    role=role,\n",
    "    framework_version=\"1.15.2\",\n",
    "    sagemaker_session = sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-graduation",
   "metadata": {},
   "source": [
    "## Try to attach job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "necessary-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tensorflow.estimator import TensorFlow\n",
    "\n",
    "# estimator = TensorFlow.attach(training_job_name='TrainingJob-20210408030418-BHHB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-receiver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
