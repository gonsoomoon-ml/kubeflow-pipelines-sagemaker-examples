{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 2] 사용자 정의 컨테이너 사용 (Bring Your Own Container)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "이 노브북을 실행하면 아래와 같은 결과를 보실 수 있습니다.\n",
    "- ![kf-pipeline.png](img/kf-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Components for Kubeflow Pipelines Example - custom container\n",
    "In this example we'll build a Kubeflow pipeline where every component call a different Amazon SageMaker feature.\n",
    "Our simple pipeline will perform:\n",
    "\n",
    "1. Hyperparameter optimization \n",
    "1. Select best hyperparameters and increase epochs\n",
    "1. Training model on the best hyperparameters \n",
    "1. Create an Amazon SageMaker model\n",
    "1. Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp import dsl\n",
    "import time, os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Component URLs are available here: <br>\n",
    "https://github.com/kubeflow/pipelines/tree/master/components/aws/sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_hpo_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/sagemaker/hyperparameter_tuning/component.yaml')\n",
    "sagemaker_train_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/sagemaker/train/component.yaml')\n",
    "sagemaker_model_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/sagemaker/model/component.yaml')\n",
    "sagemaker_deploy_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/sagemaker/deploy/component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = boto3.Session()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "sm   = sess.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training datasets and upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords.py:35: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords.py:35: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating cifar10/train/train.tfrecords\n",
      "Generating cifar10/validation/validation.tfrecords\n",
      "Generating cifar10/eval/eval.tfrecords\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "bucket_name = sagemaker_session.default_bucket()\n",
    "job_folder      = 'jobs'\n",
    "dataset_folder  = 'datasets'\n",
    "local_dataset = 'cifar10'\n",
    "\n",
    "import os\n",
    "os.makedirs(local_dataset, exist_ok=True)\n",
    "# TensorFlow is required to download and convert the dataset to TFRecord format\n",
    "!python generate_cifar10_tfrecords.py --data-dir {local_dataset}\n",
    "datasets = sagemaker_session.upload_data(path='cifar10', key_prefix='datasets/cifar10-dataset')\n",
    "\n",
    "# If dataset is already in S3 use the dataset's path:\n",
    "# datasets = 's3://{bucket_name}/{dataset_folder}/cifar10-dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your Docker container and push it to Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------\n",
    "**STOP:** Open **`/docker/build_docker_push_to_ecr.ipynb`** and follow steps to build and push container to Amazon ECR before proceeding\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a custom pipeline op\n",
    "Takes the results from a hyperparameter tuning job and increases the number of epochs for the next training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_best_model_hyperparams(hpo_results, best_model_epoch = \"80\") -> str:\n",
    "    import json\n",
    "    r = json.loads(str(hpo_results))\n",
    "    return json.dumps(dict(r,epochs=best_model_epoch))\n",
    "\n",
    "get_best_hyp_op = func_to_container_op(update_best_model_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region:  ap-northeast-2\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "print(\"region: \", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 이미지 검색\n",
    "\n",
    "Available Deep Learning Containers Images\n",
    "- https://github.com/aws/deep-learning-containers/blob/master/available_images.md\n",
    "\n",
    "특정 계정의 리파지토리 검색 명령어\n",
    "- `aws ecr describe-repositories --repository-names tensorflow-inference --registry-id 763104351884`\n",
    "\n",
    "특정 리파지토리의 Tag 검색\n",
    "- `aws ecr list-images --repository-name tensorflow-inference --registry-id 763104351884 --max-items 100 | grep 1.15.2-cpu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-northeast-2:763104351884:repository/tensorflow-inference\",\n",
      "            \"registryId\": \"763104351884\",\n",
      "            \"repositoryName\": \"tensorflow-inference\",\n",
      "            \"repositoryUri\": \"763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference\",\n",
      "            \"createdAt\": 1553139224.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! aws ecr describe-repositories --repository-names tensorflow-inference --registry-id 763104351884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            \"imageTag\": \"1.15.2-cpu-py36-ubuntu18.04-v4.4\"\n",
      "            \"imageTag\": \"1.15.2-cpu-py36-ubuntu18.04-v4.4-2020-03-19-21-33-20\"\n"
     ]
    }
   ],
   "source": [
    "! aws ecr list-images --repository-name tensorflow-inference --registry-id 763104351884 --max-items 100 | grep 1.15.2-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image = '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:1.15.2-cpu-py36-ubuntu18.04-v4.4'\n",
    "# inference_image = '763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:1.15.2-cpu'\n",
    "# inference_image = '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:1.15.2-cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='cifar10 hpo train deploy pipeline',\n",
    "    description='cifar10 hpo train deploy pipeline using sagemaker'\n",
    ")\n",
    "def cifar10_hpo_train_deploy(region= region,\n",
    "                           training_input_mode='File',\n",
    "                           train_image=f'{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-kubernetes:latest',\n",
    "                           serving_image=inference_image,\n",
    "                           volume_size='50',\n",
    "                           max_run_time='86400',\n",
    "                           instance_type='ml.p3.8xlarge',\n",
    "                           network_isolation='False',\n",
    "                           traffic_encryption='False',\n",
    "                           spot_instance='False',\n",
    "                           channels='[ \\\n",
    "                    { \\\n",
    "                        \"ChannelName\": \"train\", \\\n",
    "                        \"DataSource\": { \\\n",
    "                            \"S3DataSource\": { \\\n",
    "                                \"S3DataType\": \"S3Prefix\", \\\n",
    "                                \"S3Uri\": \"s3://'+bucket_name+'/datasets/cifar10-dataset/train\", \\\n",
    "                                \"S3DataDistributionType\": \"FullyReplicated\" \\\n",
    "                            } \\\n",
    "                        }, \\\n",
    "                        \"CompressionType\": \"None\", \\\n",
    "                        \"RecordWrapperType\": \"None\" \\\n",
    "                    }, \\\n",
    "                    { \\\n",
    "                        \"ChannelName\": \"validation\", \\\n",
    "                        \"DataSource\": { \\\n",
    "                            \"S3DataSource\": { \\\n",
    "                                \"S3DataType\": \"S3Prefix\", \\\n",
    "                                \"S3Uri\": \"s3://'+bucket_name+'/datasets/cifar10-dataset/validation\", \\\n",
    "                                \"S3DataDistributionType\": \"FullyReplicated\" \\\n",
    "                            } \\\n",
    "                        }, \\\n",
    "                        \"CompressionType\": \"None\", \\\n",
    "                        \"RecordWrapperType\": \"None\" \\\n",
    "                    }, \\\n",
    "                    { \\\n",
    "                        \"ChannelName\": \"eval\", \\\n",
    "                        \"DataSource\": { \\\n",
    "                            \"S3DataSource\": { \\\n",
    "                                \"S3DataType\": \"S3Prefix\", \\\n",
    "                                \"S3Uri\": \"s3://'+bucket_name+'/datasets/cifar10-dataset/eval\", \\\n",
    "                                \"S3DataDistributionType\": \"FullyReplicated\" \\\n",
    "                            } \\\n",
    "                        }, \\\n",
    "                        \"CompressionType\": \"None\", \\\n",
    "                        \"RecordWrapperType\": \"None\" \\\n",
    "                    } \\\n",
    "                ]'\n",
    "                          ):\n",
    "    # Component 1\n",
    "    hpo = sagemaker_hpo_op(\n",
    "        region=region,\n",
    "        image=train_image,\n",
    "        training_input_mode=training_input_mode,\n",
    "        strategy='Bayesian',\n",
    "        metric_name='val_acc',\n",
    "        metric_definitions='{\"val_acc\": \"val_acc: ([0-9\\\\\\\\.]+)\"}',\n",
    "        metric_type='Maximize',\n",
    "        static_parameters='{ \\\n",
    "            \"epochs\": \"1\", \\\n",
    "            \"momentum\": \"0.9\", \\\n",
    "            \"weight-decay\": \"0.0002\", \\\n",
    "            \"model_dir\":\"s3://'+bucket_name+'/jobs\", \\\n",
    "            \"sagemaker_region\": \"ap-northeast-2\" \\\n",
    "        }',\n",
    "        continuous_parameters='[ \\\n",
    "            {\"Name\": \"learning-rate\", \"MinValue\": \"0.0001\", \"MaxValue\": \"0.1\", \"ScalingType\": \"Logarithmic\"} \\\n",
    "        ]',\n",
    "        categorical_parameters='[ \\\n",
    "            {\"Name\": \"optimizer\", \"Values\": [\"sgd\", \"adam\"]}, \\\n",
    "            {\"Name\": \"batch-size\", \"Values\": [\"32\", \"128\", \"256\"]}, \\\n",
    "            {\"Name\": \"model-type\", \"Values\": [\"resnet\", \"custom\"]} \\\n",
    "        ]',\n",
    "        channels=channels,\n",
    "        output_location=f's3://{bucket_name}/jobs',\n",
    "        instance_type=instance_type,\n",
    "        instance_count='1',\n",
    "        volume_size=volume_size,\n",
    "        max_num_jobs='1',\n",
    "        max_parallel_jobs='1',\n",
    "        max_run_time=max_run_time,\n",
    "        network_isolation=network_isolation,\n",
    "        traffic_encryption=traffic_encryption,\n",
    "        spot_instance=spot_instance,\n",
    "        role=role\n",
    "    )\n",
    "    \n",
    "    # Component 2\n",
    "    training_hyp = get_best_hyp_op(hpo.outputs['best_hyperparameters'])\n",
    "    \n",
    "    # Component 3\n",
    "    training = sagemaker_train_op(\n",
    "        region=region,\n",
    "        image=train_image,\n",
    "        training_input_mode=training_input_mode,\n",
    "        hyperparameters=training_hyp.output,        \n",
    "        channels=channels,\n",
    "        instance_type=instance_type,\n",
    "        instance_count='1',\n",
    "        volume_size=volume_size,\n",
    "        max_run_time=max_run_time,\n",
    "        model_artifact_path=f's3://{bucket_name}/jobs',\n",
    "        network_isolation=network_isolation,\n",
    "        traffic_encryption=traffic_encryption,\n",
    "        spot_instance=spot_instance,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "    # Component 4\n",
    "    create_model = sagemaker_model_op(\n",
    "        region=region,\n",
    "        model_name=training.outputs['job_name'],\n",
    "        image=serving_image,\n",
    "        model_artifact_url=training.outputs['model_artifact_url'],\n",
    "        network_isolation=network_isolation,\n",
    "        role=role\n",
    "    )\n",
    "\n",
    "    # Component 5\n",
    "    prediction = sagemaker_deploy_op(\n",
    "        region=region,\n",
    "        model_name_1=create_model.output,\n",
    "        instance_type_1='ml.m5.large'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(cifar10_hpo_train_deploy,'sm-hpo-train-deploy-pipeline.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 잡 확인\n",
    "- 현재 아래 링크는 동작 안합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/9ac1ef33-005e-4ca2-82c9-57404d822ffc\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/44067897-aa40-423e-9d83-5a0456d82c6f\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "aws_experiment = client.create_experiment(name='aws')\n",
    "\n",
    "exp_name    = f'cifar10-hpo-train-deploy-kfp-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "my_run = client.run_pipeline(aws_experiment.id, exp_name, 'sm-hpo-train-deploy-pipeline.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 현재 추론은 에러 발생 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = 'Endpoint-20210408030418-BHHB'\n",
    "endpoint_name = 'kf-console2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from model with message \"{\"error\": \"Unsupported Media Type: application/x-image\"}\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/kf-console2 in account 189546603447 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6ec92bb7e02e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m response = client.invoke_endpoint(EndpointName= endpoint_name, \n\u001b[1;32m     11\u001b[0m                                   \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'application/x-image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                   Body=payload)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'airplane'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'automobile'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bird'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'frog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'horse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ship'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'truck'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from model with message \"{\"error\": \"Unsupported Media Type: application/x-image\"}\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/kf-console2 in account 189546603447 for more information."
     ]
    }
   ],
   "source": [
    "import json, boto3\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "file_name = '1000_dog.png'\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    \n",
    "# print(\"payload: \\n\", payload)    \n",
    "\n",
    "response = client.invoke_endpoint(EndpointName= endpoint_name, \n",
    "                                  ContentType='application/x-image', \n",
    "                                  Body=payload)\n",
    "print(response['Body'].read())\n",
    "labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에러\n",
    "\n",
    "`INFO:root:Submitting HyperParameter Tuning Job request to SageMaker...\n",
    "Traceback (most recent call last):\n",
    "  File \"hyperparameter_tuning.py\", line 95, in <module>\n",
    "    main()\n",
    "  File \"hyperparameter_tuning.py\", line 73, in main\n",
    "    hpo_job_name = _utils.create_hyperparameter_tuning_job(client, vars(args))\n",
    "  File \"/app/common/_utils.py\", line 574, in create_hyperparameter_tuning_job\n",
    "    raise Exception(e.response['Error']['Message'])\n",
    "Exception: User: arn:aws:sts::189546603447:assumed-role/eksctl-cluster-nodegroup-cpu-node-NodeInstanceRole-1TH85QZIZHJEA/i-09a03423d5bc7f8f4 is not authorized to perform: sagemaker:CreateHyperParameterTuningJob on resource: arn:aws:sagemaker:ap-northeast-2:189546603447:hyper-parameter-tuning-job/hpojob-20210408021532-53nh\n",
    "11\n",
    "`\n",
    "\n",
    "- IAM Role (eksctl-cluster-nodegroup-cpu-node-NodeInstanceRole-1TH85QZIZHJEA/i-09a03423d5bc7f8f4) 에 SageMakerFullAccess 정책을 추가 해주세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
